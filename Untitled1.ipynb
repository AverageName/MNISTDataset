{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "%matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5))])\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    './data', train=True, transform=transform, download=True)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,batch_size=4,shuffle=True,num_workers=2)\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    './data', train=False, transform=transform, download=True)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "classes = ('0', '1','2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,16,5)\n",
    "        self.conv2 = nn.Conv2d(16,20,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv3 = nn.Conv2d(20,120,4)\n",
    "        self.conv4 = nn.Conv2d(120,84,1)\n",
    "        self.conv5 = nn.Conv2d(84,10,1)\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.conv5(x)\n",
    "        return x\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 ,  2000] loss: 1.156\n",
      "[1 ,  4000] loss: 0.189\n",
      "[1 ,  6000] loss: 0.134\n",
      "[1 ,  8000] loss: 0.098\n",
      "[1 , 10000] loss: 0.093\n",
      "[1 , 12000] loss: 0.085\n",
      "[1 , 14000] loss: 0.079\n",
      "[2 ,  2000] loss: 0.064\n",
      "[2 ,  4000] loss: 0.055\n",
      "[2 ,  6000] loss: 0.049\n",
      "[2 ,  8000] loss: 0.058\n",
      "[2 , 10000] loss: 0.045\n",
      "[2 , 12000] loss: 0.052\n",
      "[2 , 14000] loss: 0.053\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    \n",
    "    sum_loss = 0.0\n",
    "    for i,data in enumerate(trainloader, 0):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        outputs = torch.squeeze(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_loss +=loss.data[0]\n",
    "        if i%2000 == 1999 :\n",
    "            print('[%d , %5d] loss: %.3f' %\n",
    "                  (epoch + 1,i + 1,sum_loss / 2000))\n",
    "            sum_loss = 0.0\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-39ca67d7a3cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ground Truth:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%5s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/max/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3155\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3156\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3157\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3158\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/max/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/max/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5122\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5124\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5125\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/max/anaconda3/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    598\u001b[0m         if (self._A.ndim not in (2, 3) or\n\u001b[1;32m    599\u001b[0m                 (self._A.ndim == 3 and self._A.shape[-1] not in (3, 4))):\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imcache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njjp5sn4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c14d42ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "plt.imshow(torchvision.utils.make_grid(images).numpy())\n",
    "print('Ground Truth:',' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "\n",
    "outputs = net(Variable(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "boo = torchvision.utils.make_grid(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 122])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boo.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:     6     4     3     2\n"
     ]
    }
   ],
   "source": [
    "_, predictions = torch.max(outputs.data, 1)\n",
    "predictions = predictions.numpy().squeeze(1)\n",
    "print('Predicted:',' '.join('%5s' % classes[predictions[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test 98.66\n"
     ]
    }
   ],
   "source": [
    "correct = 0 \n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images,labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predictions = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predictions == labels).sum()\n",
    "print('Accuracy for test',100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
