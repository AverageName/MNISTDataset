{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "%matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=(0.5,0.5,0.5),std=(0.5,0.5,0.5))])\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    './data', train=True, transform=transform, download=True)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,batch_size=4,shuffle=True,num_workers=2)\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    './data', train=False, transform=transform, download=True)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "classes = ('0', '1','2', '3', '4', '5', '6', '7', '8', '9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,16,5)\n",
    "        self.conv2 = nn.Conv2d(16,20,5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv3 = nn.Conv2d(20,120,4)\n",
    "        self.conv4 = nn.Conv2d(120,84,1)\n",
    "        self.conv5 = nn.Conv2d(84,10,1)\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.conv5(x)\n",
    "        return x\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 ,  2000] loss: 1.024\n",
      "[1 ,  4000] loss: 0.179\n",
      "[1 ,  6000] loss: 0.131\n",
      "[1 ,  8000] loss: 0.110\n",
      "[1 , 10000] loss: 0.083\n",
      "[1 , 12000] loss: 0.080\n",
      "[1 , 14000] loss: 0.073\n",
      "[2 ,  2000] loss: 0.063\n",
      "[2 ,  4000] loss: 0.058\n",
      "[2 ,  6000] loss: 0.053\n",
      "[2 ,  8000] loss: 0.057\n",
      "[2 , 10000] loss: 0.052\n",
      "[2 , 12000] loss: 0.053\n",
      "[2 , 14000] loss: 0.046\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    \n",
    "    sum_loss = 0.0\n",
    "    for i,data in enumerate(trainloader, 0):\n",
    "        \n",
    "        inputs, labels = data\n",
    "        \n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        outputs = torch.squeeze(outputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_loss +=loss.data[0]\n",
    "        if i%2000 == 1999 :\n",
    "            print('[%d , %5d] loss: %.3f' %\n",
    "                  (epoch + 1,i + 1,sum_loss / 2000))\n",
    "            sum_loss = 0.0\n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth:     9     9     7     2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAB6CAYAAACr63iqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1LGLiGSMOnYRkYxRxy4ikjH/D1kuEu0RipSmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3805e5d4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('Ground Truth:',' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "\n",
    "outputs = net(Variable(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for test 98.95\n"
     ]
    }
   ],
   "source": [
    "correct = 0 \n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images,labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predictions = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predictions == labels).sum()\n",
    "print('Accuracy for test',100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
